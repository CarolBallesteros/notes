Cuando estamos trabajando en nuestra máquina local, Docker dispone de las capas de todas las ejecuciones previas de docker build que hemos realizado. En otras palabras, cuando trabajamos en nuestra máquina local la caché de Docker está inicializada, recuerda la ejecución de instrucciones docker build anteriores, y como hemos visto en lecciones anteriores, optimiza enormemente la generación de imágenes. Sin embargo, esto no suele ser así en entornos de integración continua, donde normalmente cada tarea de integración (ya sea el build de una imagen o la ejecución de tests) se ejecuta en una nueva máquina independiente creada para este fin, y destruída cuando la tarea acaba. Esto es así porque reusar las mismas máquinas entre tareas de integración continua puede conllevar la aparición de estados indeseados en la máquina, o la acumulación de basura que terminará saturando los recursos de dicha máquina. En consecuencia, cuando una tarea de integración continua se ejecuta, es bastante frecuente que la cache de Docker no esté inicializada, lo que implica que los tiempos para construir nuestras imágenes pueden crecer enormemente. Esto es un problema importante porque idealmente las tareas de integración continua deben ejecutar cuanto más rápido mejor.
Por suerte Docker tiene una solución a este problema. Cuando ejecutamos un docker build podemos indicar que utilice la caché de una imagen ya creada. Dicho de otra manera, si estoy construyendo la imagen openwebinars/docker-for-devs:latest, puedo reusar la cache de la última versión de openwebinars/docker-for-devs:latest ejecutando estos commandos:
docker pull openwebinars/docker-for-devs:latest
docker build -t openwebinars/docker-for-devs:latest --cache-from=openwebinars/docker-for-devs:latest